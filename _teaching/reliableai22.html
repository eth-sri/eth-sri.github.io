---
title: Reliable and Trustworthy Artificial Intelligence
ref: reliableai2022
description: Graduate course involving the analysis, robustness and visualization of neural networks.
semester: Fall 2022
number: 263-2400-00L
lecturer: Prof. Dr. Martin Vechev
ta: Maximilian Baader, Mislav Balunovic, Benjamin Bichsel, Dimitar I. Dimitrov Marc Fischer, Jingxuan He, Nikola Jovanović, Nikola Konstantinov, Mark Niklas Müller, Momchil Peychev, Samuel Steffen
assistants:
head-ta: Benjamin Bichsel
head-ta-details: use <a href="https://moodle-app2.let.ethz.ch/course/view.php?id=15505">Moodle</a> for questions whenever possible
edoz: http://www.vvz.ethz.ch/Vorlesungsverzeichnis/lerneinheit.view?lerneinheitId=163199&semkez=2022W&ansicht=LEHRVERANSTALTUNGEN&lang=de
session-time-place:
lecture-time-place: Wed 14-16, HG G3 (<a href="youtube">recordings</a>)
exercise-time-place: Mon 12-14 or Wed 12-14, CAB G51
credits: 6
image: assets/images/reliableai_logo.png
---

<h2>Overview</h2>

<p>
	Creating robust, fair and trustworthy machine learning models is a fundamental challenge to solving the artificial intelligence problem, one of fundamental and increasing importance in our society. This course covers some of the latest and most exciting research advances that bring us closer to constructing such models.
	Upon completion of the course, the students should have mastered the underlying methods, be able to apply them to a variety of problems, and be able to conduct research in the space. To facilitate deeper understanding, an important part of the course will be a group hands-on programming project where students will build a system based on the learned material.
	</p>
	<p>The course covers some of the latest research (over the last 3 years) underlying the creation of robust, fair and trustworthy AI:</p>
	<ul>
	<li>Adversarial Attacks on Deep Learning (noise-based, geometry attacks, sound attacks, physical attacks, autonomous driving, out-of-distribution)</li>
	<li>Defenses against attacks</li>
	<li>Combining gradient-based optimization with logic for encoding background knowledge</li>
	<li>Complete Certification of deep neural networks via automated reasoning (e.g., via numerical abstractions, mixed-integer solvers)</li>
	<li>Probabilistic certification of deep neural networks</li>
	<li>Training deep neural networks to be provably robust</li>
	<li>Creating provably fair and unbiased deep models</li>
</ul>

<h2 id="lectures">Lectures</h2>

<p>Use your NETHZ account to access the files.</p>

<table centering border="0" width="100%" cellspacing="0" cellpadding="0">

	<th width="10%">Date</th>
	<th width=50%>Content</th>
	<th width=10%>Recording</th>
	<th width="10%">Slides</th>
	<th width=10%>Exercises</th>
	<th width=10%>Solutions</th>

<tr>
	<td>Sept 21</td>
	<td>Introduction</td>
	<td></td>  
	<td></td>
	<td></td>
	<td></td>
</tr>

</table>



<p>
	All lectures from this year are
	collected in a <a
	href="https://www.youtube.com/playlist?list=PLWjm4hHpaNg4Jkmz1PujM3jRbYnzD0WBY">Youtube
	playlist (2021)</a>. All lecture recordings from 2020 are in
	another
	<a
	href="https://www.youtube.com/playlist?list=PLWjm4hHpaNg6c-W7JjNYDEC_kJK9oSp0Y">Youtube
	playlist (2020)</a>. Note that some topics changed since 2020.
</p>

<h2 id="project">Course project</h2>

<p>Details on the course project will be added here.</p>

<h2 id="previous-exams">Previous Exams</h2>

<p>
Previous exams (formerly, this course was named "Reliable and Interpretable
Artificial Intelligence") are available in the <a
href="https://exams.vis.ethz.ch/">exam collection</a> of the student association
(VIS).
</p>

<h2 id="course-organization">Course Organization</h2>

<p><strong>Lectures</strong></p>

<ul>
	<li>
		For additional questions, we have prepared a <a
		href="https://moodle-app2.let.ethz.ch/course/view.php?id=15505">Moodle
		forum</a>.
	</li>
</ul>

<p><strong>Exercises</strong></p>

<ul>
	<li>
		All exercise sessions will be physical. Attending the exercise sessions
		is optional.
	</li>
	<li>
		The first exercise sessions (September 27 and September 29) will be a
		general introduction to some prerequisites for the course, and will not
		involve an exercise sheet. The covered material should be familiar to
		most students, and the slides discussed in the session will be available
		online.
	</li>
	<li>Every week, we will publish an exercise sheet and its solutions <a
	href="https://www.sri.inf.ethz.ch/teaching/reliableai22">here</a>, by
	Thursday evening.</li>
	<li>We strongly recommend to solve the exercises before next week's exercise
	session, and before looking at the solutions. The style of the exam will be
	similar to the exercises, so first-hand experience solving exercises is
	critical.</li>
	<li>The exercise sessions will be in a Q&A format, where you can ask
	questions about the exercise sheet (and its solutions) from the previous
	week.</li>
	<li>We will not cover additional material in the exercise sessions.
	Therefore, we will also not record the exercise sessions (we believe this
	will encourage students to ask more questions).</li>
	<li>For additional questions, we have prepared a <a
	href="">Moodle
	forum</a>.</li>
	<li>In case there are not enough questions for the full exercise session, we
	will stop it early.</li>
	<li>There is no need to attend both exercise sessions, as their contents
	will be equivalent.</li>
</ul>

<p><strong>Communication</strong></p>

<p>
All communication (like special announcements) will be sent out by e-mail.
</p>

<h2>Literature</h2>

<p>
For students who would like to brush up on the basics of machine learning used
in this course, we recommend
</p>

<ul>
	<li>Section 3 (Background) of the publication <a
	href="https://files.sri.inf.ethz.ch/website/papers/DeepPoly.pdf">An Abstract
	Domain for Certifying Neural Networks</a> by Gagandeep Singh, Timon Gehr,
	Markus Püschel, and Martin Vechev</li>
	<li><a href="http://neuralnetworksanddeeplearning.com/index.html">Neural
	Networks and Deep Learning</a> by Michael Nielsen</li>
	<li><a href="https://www.deeplearningbook.org/">Deep Learning book</a>
	by Ian Goodfellow, Yoshua Bengio, and Aaron Courville</li>
</ul>
