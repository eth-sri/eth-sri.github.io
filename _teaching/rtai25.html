---
title: Reliable and Trustworthy Artificial Intelligence
ref: rtai2025
description: A graduate course discussing the foundations and emerging methods for building reliable and trustworthy AI systems.
semester: Fall 2025
number: 263-2400-00L
lecturer: Prof. Dr. Martin Vechev
ta: Jasper Dekoninck, Giovanni De Muri, Kazuki Egashira, Thibaud Gloaguen, Nikola Jovanović, Yuhao Mao, Robin Staab, Chenhao Sun
assistants:
head-ta: Nikola Jovanović
head-ta-details: use <a href="https://moodle-app2.let.ethz.ch/course/view.php?id=26138">Moodle</a> for questions unless they contain sensitive information
edoz: https://www.vorlesungen.ethz.ch/Vorlesungsverzeichnis/lerneinheit.view?semkez=2025W&ansicht=LEHRVERANSTALTUNGEN&lerneinheitId=193777&lang=en
session-time-place:
lecture-time-place: Wed 14-16,&nbsp;<a href="https://ethz.ch/en/utils/location.html?building=HG&floor=G&room=3&lang=en">HG G 3</a>&nbsp;(<a href="https://video.ethz.ch/">recordings on the ETH video portal</a>)
exercise-time-place: Mon 12-14,&nbsp;<a href="https://ethz.ch/en/utils/location.html?building=CAB&floor=G&room=56&lang=en">CAB G 56</a>&nbsp;or Wed 12-14,&nbsp;<a href="https://ethz.ch/en/utils/location.html?building=CAB&floor=G&room=51&lang=en">CAB G 51</a>
credits: 6
image: assets/images/reliableai_logo.png
---

<h2>Overview</h2>

<p>
	Reliability, security, privacy, and robustness are core challenges in achieving trustworthy AI and are of
	fundamental importance. The goal of this course is to teach both the mathematical foundations of this emerging field
	and to introduce students to the latest and most exciting advances. To facilitate deeper understanding, the course
	includes a group coding project where students will build a system based on the learned material.</p>

<p>The course is structured in three parts:</p>

<p><b>Robustness in Machine Learning</b></p>
<ul>
	<li>Adversarial attacks and defenses on deep learning models.</li>
	<li>Automated certification of deep learning models (convex relaxations, branch and bound, randomized smoothing).
	</li>
	<li>Certified training of deep neural networks (combining symbolic and continuous methods).</li>
	<li>State-of-the-art attacks and novel attack vectors for large language models (LLMs).</li>
</ul>

<p><b>Privacy in Machine Learning</b></p>
<ul>
	<li>Threat models (e.g., data stealing, model poisoning, membership inference).</li>
	<li>Privacy attacks in decentralized (federated) machine learning.</li>
	<li>Protection via differential privacy; applications to centralized and decentralized model training.</li>
	<li>Memorization in generative AI models; training data extraction attacks.</li>
	<li>Private attribute inference with generative AI models.</li>
	<li>Securing data flows in agentic AI systems.</li>
</ul>

<p><b>Provenance and Evaluation in Generative AI</b></p>
<ul>
	<li>Reliable detection of AI-generated content via watermarking.</li>
	<li>Removing and forging watermarks; data watermarking.</li>
	<li>Dataset contamination: detecting and evading detection.</li>
	<li>Trustworthy evaluation of LLMs: challenges in benchmarking and rating.</li>
	<li>Bridging AI regulation (e.g., EU AI Act) and technical evaluations.</li>
</ul>

<h2 id="lectures">Lectures</h2>

<p>Use your NETHZ account to access the files.</p>

<table centering border="0" width="100%" cellspacing="0" cellpadding="0">

	<th width="10%">Date</th>
	<th width=60%>Content</th>
	<th width="10%">Slides</th>
	<th width=10%>Exercises</th>
	<th width=10%>Solutions</th>

	<tr>
		<td>Sep 17</td>
		<td>Course Introduction</td>
		<td>
			<a href="https://files.sri.inf.ethz.ch/website/teaching/reliableai2025/materials/slides/LECTURE1_INTRO.pdf" class="pdf" title="">
				<img src="/assets/icons/icon-slides.svg" class="svg-icon" border="0" alt="PDF">
			</a>
		</td>
		<td>
			<a class="pdf"
				href="https://files.sri.inf.ethz.ch/website/teaching/reliableai2025/materials/exercises/exercise_1/Exercise01.pdf"
				title="Exercise 01 Slides"><img src="/assets/icons/icon-slides.svg" class="svg-icon" alt="PDF" border="0"></a>
		</td>
		<td>
		</td>
	</tr>
	<tr>
		<td>Sep 24</td>
		<td>Adversarial Attacks and Defenses</td>
		<td>
			<a href="https://files.sri.inf.ethz.ch/website/teaching/reliableai2025/materials/slides/LECTURE2_ATTACKS_DEFENSES.pdf" class="pdf" title="">
				<img src="/assets/icons/icon-slides.svg" class="svg-icon" border="0" alt="PDF">
			</a>
		</td>  
		<td>
			<!-- TODO -->
		</td>
		<td>
			<!-- TODO -->
		</td>
	</tr>

</table>

<h2 id="recordings">Recordings</h2>

<p>
	All lecture recordings from this year will be available on the ETH video portal, in the same way as <a
		href="https://video.ethz.ch/lectures/d-infk/2024/autumn/263-2400-00L.html">the recordings from 2024</a>. Another
	useful resource is our <a href="https://www.youtube.com/playlist?list=PLWjm4hHpaNg6c-W7JjNYDEC_kJK9oSp0Y">Youtube
		playlist of lecture recordings from 2020</a>. However, note that the course syllabus has been significantly
	modified in the meantime.
</p>

<h2 id="project">Course Project</h2>

<p>To be announced.</p>

<h2 id="previous-exams">Previous Exams</h2>

<p>
	Previous exams (formerly, this course was named "Reliable and Interpretable
	Artificial Intelligence") are available in the <a href="https://exams.vis.ethz.ch/">exam collection</a> of the
	student association
	(VIS).
</p>

<h2 id="course-organization">Course Organization</h2>

<p><strong>Lectures</strong></p>

<ul>
	<li>The lecture will take place physically in room HG G 3, but will be recorded.</li>
	<li>
		For additional questions, we have prepared a <a
			href="https://moodle-app2.let.ethz.ch/course/view.php?id=26138">Moodle
			forum</a>.
	</li>
</ul>

<p><strong>Exercises</strong></p>

<ul>
	<li>Every week, we will publish an exercise sheet and its solutions on this
		page, by Thursday evening.</li>
	<li>The exercise session will consist of a discussion of selected exercises
		(potentially not all exercises). On demand, the teaching assistant can also
		discuss questions on specific exercises brought up by students.</li>
	<li>Some exercise sessions will also discuss prerequisites for the course.
		The material covered in these sessions will be available online. This will
		be the case in the first exercise on Sep 22/24. For other
		exercise sessions, we will announce by mail if they discuss
		prerequisites.</li>
	<li>Attending the exercise sessions is optional. We will not cover new material in the exercise sessions,
		except for prerequisites (see above). Therefore, we will also not record the exercise sessions.
	</li>
	<li>We strongly recommend solving the exercises before next week's exercise
		session, and before looking at the solutions. The style of the exam will be
		similar to the exercises, so first-hand experience solving exercises is
		critical.</li>
	<li>For additional questions, we have prepared a <a
			href="https://moodle-app2.let.ethz.ch/course/view.php?id=26138">Moodle
			forum</a>.</li>
	<li>There is no need to attend both exercise sessions, as their contents
		will be equivalent.</li>
</ul>

<p><strong>Communication</strong></p>

<p>
	All communication (e.g., special announcements) will be sent out by e-mail.
</p>

<h2>Prerequisites</h2>

<p>While not a formal requirement, the course assumes a good understanding of linear algebra, analysis, probability
	theory and machine learning (especially neural networks). These topics are usually covered in “Intro to ML” classes
	at most institutions (e.g., “Introduction to Machine Learning” at ETH). </p>

<p>The coding project will utilize Python and PyTorch. Thus programming experience in Python is expected. Students
	without prior knowledge of PyTorch are expected to acquire it prior to the course.</p>

<h2>Literature</h2>

<p>
	For students who would like to brush up on the basics of machine learning used
	in this course, we recommend
</p>

<ul>
	<li>Section 3 (Background) of the publication <a href="https://files.sri.inf.ethz.ch/website/papers/DeepPoly.pdf">An
			Abstract
			Domain for Certifying Neural Networks</a> by Gagandeep Singh, Timon Gehr,
		Markus Püschel, and Martin Vechev</li>
	<li><a href="http://neuralnetworksanddeeplearning.com/index.html">Neural
			Networks and Deep Learning</a> by Michael Nielsen</li>
	<li><a href="https://www.deeplearningbook.org/">Deep Learning book</a>
		by Ian Goodfellow, Yoshua Bengio, and Aaron Courville</li>
</ul>