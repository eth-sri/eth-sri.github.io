---
title: Reliable and Interpretable Artificial Intelligence
ref: riai2019
description: Graduate course involving the analysis, robustness and visualization of neural networks, as well as probabilistic programming.
semester: Fall 2019
number: 263-2400-00L
lecturer: Prof. Dr. Martin Vechev
ta: Dr. Petar Tsankov, Benjamin Bichsel, Samuel Steffen, Gagandeep Singh, Mislav Balunovic, Marc Fischer, Maximilian Baader, Jingxuan He
assistants:
edoz: http://vvz.ethz.ch/Vorlesungsverzeichnis/lerneinheit.view?lerneinheitId=131566&semkez=2019W&ansicht=KATALOGDATEN&lang=de
session-time-place:
lecture-time-place: Wed 15-17, HG G 3
exercise-time-place: Mon 13-14, LFW C4 or Wed 11-12 CAB G59
credits: 5
image: ai.png
---

<h2>Overview</h2>

<p>
  Creating reliable and explainable probabilistic models is a fundamental challenge to solving the artificial intelligence problem. This course covers some of the latest and most exciting advances that bring us closer to constructing such models.

The main objective of this course is to expose students to the latest and most exciting research in the area of explainable and interpretable artificial intelligence, a topic of fundamental and increasing importance. Upon completion of the course, the students should have mastered the underlying methods and be able to apply them to a variety of problems.

To facilitate deeper understanding, an important part of the course will be a group hands-on programming project where students will build a system based on the learned material.
</p>

<p>The course covers some of the latest research (over the last 2-3 years) underlying the creation of safe, trustworthy, and reliable AI:</p>

<ul>
<li>Adversarial Attacks on Deep Learning (noise-based, geometry attacks, sound attacks, physical attacks, autonomous driving, out-of-distribution)</li>
<li>Defenses against attacks</li>
<li>Combining gradient-based optimization with logic for encoding background knowledge</li>
<li>Complete Certification of deep neural networks via automated reasoning (e.g., via numerical abstractions, mixed-integer solvers)</li>
<li>Probabilistic certification of deep neural networks</li>
<li>Training deep neural networks to be provably robust via automated reasoning</li>
<li>Understanding and Interpreting Deep Networks</li>
<li>Probabilistic Programming</li>
</ul>

<!--
To gain a deeper understanding of the material and be able to apply and extend the concepts, an important part of the course will be a group hands-on programming project where students will build a system based on the learned material.

While we do cover the latest material, the course should be self-contained and any necessary background will be introduced in the lectures or in exercise sessions (e.g., basics of deep learning) together with additional pointers if needed. -->

<!--
<h2> Course project</h2>
-->

<h2>Lectures</h2>
<table centering border="0" width="100%" cellspacing="0" cellpadding="0">
<th width=7%>No.</th> <th width="10%">Date</th><th width=43%>Content</th><th width="12%">Slides</th><th width=15%> Exercises </th><th width=13%> Solutions </th>


<tr>
<td>1</td>
<td>Sept 18</td>
<td>Introduction</td>
<td><a href="https://files.sri.inf.ethz.ch/website/teaching/riai2019/materials/slides/intro.pdf" class="pdf" title="intro"><img src="/assets/icons/icon-slides.svg" class="svg-icon" border="0" alt="PDF"></a></td>
<td><a class="pdf"
href="https://files.sri.inf.ethz.ch/website/teaching/riai2019/materials/exercises/Exercise01.pdf"
title="Exercise 1"><img src="/assets/icons/icon-slides.svg" class="svg-icon" alt="PDF" border="0"></a></td>
<td></td>
</tr>

<tr>
	<td>2</td>
	<td>Sept 25</td>
	<td>Adversarial attacks I</td>
	<td><a href="https://files.sri.inf.ethz.ch/website/teaching/riai2019/materials/slides/LECTURE2_ATTACK.pdf" class="pdf" title="Adversarial attacks"><img src="/assets/icons/icon-slides.svg" class="svg-icon" border="0" alt="PDF"></a></td>
  <td><a class="pdf" href="https://files.sri.inf.ethz.ch/website/teaching/riai2019/materials/exercises/Exercise02.pdf"
title="Exercise 02"><img src="/assets/icons/icon-pdf.svg" class="svg-icon" alt="PDF" border="0"></a>
  <a class="pdf" href="https://files.sri.inf.ethz.ch/website/teaching/riai2019/materials/exercises/Exercise02_fgsm.py"
title="Exercise 02 FGSM.py"><img src="/assets/icons/icon-download.svg" class="svg-icon" alt="PDF" border="0"></a>
  </td>
	<td>
      <a class="pdf" href="https://files.sri.inf.ethz.ch/website/teaching/riai2019/materials/exercises/Solution02.pdf"
title="Solution 02"><img src="/assets/icons/icon-pdf.svg" class="svg-icon" alt="PDF" border="0"></a>
      <a class="pdf" href="https://files.sri.inf.ethz.ch/website/teaching/riai2019/materials/exercises/Exercise02_fgsm_solution.py"
title="Exercise 02 FGSM_Solution.py"><img src="/assets/icons/icon-download.svg" class="svg-icon" alt="PDF" border="0"></a>
      <a class="pdf" href="https://files.sri.inf.ethz.ch/website/teaching/riai2019/materials/exercises/Exercise02_pytorch_mnist_train.ipynb"
title="Exercise 02 Jupyter Notebook"><img src="/assets/icons/icon-download.svg" class="svg-icon" alt="PDF" border="0"></a>
  </td>
	</tr>

<tr>
	<td>3</td>
	<td>Oct 2</td>
	<td>Adversarial attacks II</td>
	<td><a href="https://files.sri.inf.ethz.ch/website/teaching/riai2019/materials/slides/LECTURE2_ATTACK.pdf" class="pdf" title="Adversarial attacks"><img src="/assets/icons/icon-slides.svg" class="svg-icon" border="0" alt="PDF"></a></td>
  <td>
    <a href="https://files.sri.inf.ethz.ch/website/teaching/riai2019/materials/exercises/Exercise03.pdf" title="Exercise 03"><img src="/assets/icons/icon-pdf.svg" class="svg-icon" alt="PDF" border="0"></a>
    <a href="https://files.sri.inf.ethz.ch/website/teaching/riai2019/materials/exercises/Exercise03.zip" title="Exercise 03 material"><img src="/assets/icons/icon-download.svg" class="svg-icon" border="0"></a>
  </td>
  <td>
    <a href="https://files.sri.inf.ethz.ch/website/teaching/riai2019/materials/exercises/Solution03.pdf" tilte="Solution 03"><img src="/assets/icons/icon-pdf.svg" class="svg-icon" alt="PDF" border="0"></a>
    <a href="https://files.sri.inf.ethz.ch/website/teaching/riai2019/materials/exercises/Solution03.zip" title="Solution 03 material"><img src="/assets/icons/icon-download.svg" class="svg-icon" border="0"></a>
  </td>
</tr>

<tr>
	<td>4</td>
	<td>Oct 9</td>
	<td>Adversarial defenses + Certification</td>
	<td><a href="https://files.sri.inf.ethz.ch/website/teaching/riai2019/materials/slides/LECTURE3_DEFENSE.pdf" class="pdf" title="Adversarial defenses"><img src="/assets/icons/icon-slides.svg" class="svg-icon" border="0" alt="PDF"></a></td>
  <td>
    <a href="https://files.sri.inf.ethz.ch/website/teaching/riai2019/materials/exercises/Exercise04.pdf" title="Exercise 04"><img src="/assets/icons/icon-pdf.svg" class="svg-icon" alt="PDF" border="0"></a>
    <a href="https://files.sri.inf.ethz.ch/website/teaching/riai2019/materials/exercises/Exercise04.zip" title="Exercise 04 material"><img src="/assets/icons/icon-download.svg" class="svg-icon" border="0"></a>
  </td>
  <td>
    <a href="https://files.sri.inf.ethz.ch/website/teaching/riai2019/materials/exercises/Solution04.pdf" tilte="Solution 04"><img src="/assets/icons/icon-pdf.svg" class="svg-icon" alt="PDF" border="0"></a>
    <a href="https://files.sri.inf.ethz.ch/website/teaching/riai2019/materials/exercises/Solution04.zip" title="Solution 04 material"><img src="/assets/icons/icon-download.svg" class="svg-icon" border="0"></a>
  </td>
 </tr>

<tr>
	<td>5</td>
	<td>Oct 16</td>
	<td>Box and MILP certification</td>
	<td><a href="https://files.sri.inf.ethz.ch/website/teaching/riai2019/materials/slides/LECTURE4_VERIFY.pdf" class="pdf" title="Box and MILP cerficitation"><img src="/assets/icons/icon-slides.svg" class="svg-icon" border="0" alt="PDF"></a><a href="https://files.sri.inf.ethz.ch/website/teaching/riai2019/materials/slides/blackboard_2019-10-16_relu_milp.pdf" title="Blackboard notes (encoding ReLU as MILP)"><img src="/assets/icons/icon-pdf.svg" class="svg-icon" alt="PDF" border="0"></a></td>
  <td>
   <a href="https://files.sri.inf.ethz.ch/website/teaching/riai2019/materials/exercises/Exercise05.pdf" title="Exercise 05"><img src="/assets/icons/icon-pdf.svg" class="svg-icon" alt="PDF" border="0"></a>
  </td>
  <td>
    &nbsp;
  </td>
 </tr>

<tr>
	<td>6</td>
	<td>Oct 23</td>
	<td>Zonotope approximation</td>
	<td><a href="https://files.sri.inf.ethz.ch/website/teaching/riai2019/materials/slides/LECTURE5_ZONOTOPE.pdf" class="pdf" title="Zonotope approximation"><img src="/assets/icons/icon-slides.svg" class="svg-icon" border="0" alt="PDF"></a></td>
  <td>
    &nbsp;
  </td>
  <td>
    &nbsp;
  </td>
 </tr>

</table>

