---
title: Reliable and Trustworthy Artificial Intelligence
ref: rtai2022
description: Graduate course involving the analysis, robustness and visualization of neural networks.
semester: Fall 2022
number: 263-2400-00L
lecturer: Prof. Dr. Martin Vechev
ta: Maximilian Baader, Mislav Balunović, Benjamin Bichsel, Dimitar I. Dimitrov, Marc Fischer, Jingxuan He, Nikola Jovanović, Nikola Konstantinov, Mark Niklas Müller, Momchil Peychev, Samuel Steffen
assistants:
head-ta: Benjamin Bichsel
head-ta-details: use <a href="https://moodle-app2.let.ethz.ch/course/view.php?id=17747">Moodle</a> for questions whenever possible
edoz: http://www.vvz.ethz.ch/Vorlesungsverzeichnis/lerneinheit.view?lerneinheitId=163199&semkez=2022W&ansicht=LEHRVERANSTALTUNGEN&lang=de
session-time-place:
lecture-time-place: Wed 14-16, HG G3 (<a href="https://www.youtube.com/playlist?list=PLWjm4hHpaNg4Jkmz1PujM3jRbYnzD0WBY">recordings</a>)
exercise-time-place: Mon 12-14 or Wed 12-14, Online (<a href="Zoom-link">Zoom link</a>)
credits: 6
image: assets/images/reliableai_logo.png
---

<h2>Overview</h2>

<p>
	Creating reliable, secure, robust, and fair machine learning models is a core challenge in artificial intelligence and one of fundamental importance. The goal of the course is to teach both the mathematical foundations of this new and emerging area as well as to introduce students to the latest and most exciting research in the space. To facilitate deeper understanding, the course includes a group project where students  build a system based on the learned material.
</p>
<p>The course is split into 3 parts:</p>

<p><b>Robustness in Deep Learning</b></p>
<ul>
	<li>Adversarial attacks and defenses on deep learning models.</li>
	<li>Automated certification of deep learning models (covering the major
	trends: convex relaxations and branch-and-bound methods as well as
	randomized smoothing).</li>
	<li>Certified training of deep neural networks to satisfy given properties (combining symbolic and continuous methods).</li>
</ul>

<p><b>Privacy of Machine Learning</b></p>
<ul>
	<li>Threat models (e.g., stealing data, poisoning, membership inference,
	etc.).</li>
	<li>Attacking federated machine learning (across modalities such as vision,
	natural language and tabular).</li>
	<li>Differential privacy for defending machine learning.</li>
	<li>Enforcing regulations with guarantees (e.g., via provable data minimization).</li>
</ul>

<p><b>Fairness of Machine Learning</b></p>
<ul>
	<li>Introduction to fairness (motivation, definitions).</li>
	<li>Enforcing individual fairness with guarantees (e.g., for both vision or tabular data).</li>
	<li>Enforcing group fairness with guarantees.</li>
</ul>

<h2 id="lectures">Lectures</h2>

<p>Use your NETHZ account to access the files.</p>

<table centering border="0" width="100%" cellspacing="0" cellpadding="0">

	<th width="10%">Date</th>
	<th width=50%>Content</th>
	<th width=10%>Recording</th>
	<th width="10%">Slides</th>
	<th width=10%>Exercises</th>
	<th width=10%>Solutions</th>

<tr>
	<td>Sept 21</td>
	<td>Introduction</td>
	<td></td>  
	<td></td>
	<td></td>
	<td></td>
</tr>

</table>



<p>
	All lectures from this year are collected in a <a
	href="https://www.youtube.com/playlist?list=PLWjm4hHpaNg4Jkmz1PujM3jRbYnzD0WBY">Youtube
	playlist (2022)</a>. While we do not provide recordings from 2021, all
	lecture recordings from 2020 are in another
	<a
	href="https://www.youtube.com/playlist?list=PLWjm4hHpaNg6c-W7JjNYDEC_kJK9oSp0Y">Youtube
	playlist (2020)</a>. Note that this 2022 version of the course contains
	several new topics not found in the 2020 and 2021 versions.
</p>

<h2 id="project">Course project</h2>

<p>Details on the course project will be added here.</p>

<h2 id="previous-exams">Previous Exams</h2>

<p>
Previous exams (formerly, this course was named "Reliable and Interpretable
Artificial Intelligence") are available in the <a
href="https://exams.vis.ethz.ch/">exam collection</a> of the student association
(VIS).
</p>

<h2 id="course-organization">Course Organization</h2>

<p><strong>Lectures</strong></p>

<ul>
	<li>
		For additional questions, we have prepared a <a
		href="https://moodle-app2.let.ethz.ch/course/view.php?id=17747">Moodle
		forum</a>.
	</li>
</ul>

<p><strong>Exercises</strong></p>

<ul>
	<li>All exercise sessions will be virtual. Attending the exercise sessions
	is optional.</li>
	<li>The first exercise sessions will be on September 26 and September 28.</li>
	<li>Every week, we will publish an exercise sheet and its solutions <a
	href="https://www.sri.inf.ethz.ch/teaching/reliableai22">here</a>, by
	Thursday evening.</li>
	<li>We strongly recommend to solve the exercises before next week's exercise
	session, and before looking at the solutions. The style of the exam will be
	similar to the exercises, so first-hand experience solving exercises is
	critical.</li>
	<li>The exercise sessions will be in a Q&A format, where you can ask
	questions about the exercise sheet (and its solutions) from the previous
	week.</li>
	<li>We will not cover additional material in the exercise sessions.
	Therefore, we will also not record the exercise sessions (we believe this
	will encourage students to ask more questions).</li>
	<li>For additional questions, we have prepared a <a
	href="https://moodle-app2.let.ethz.ch/course/view.php?id=17747">Moodle
	forum</a>.</li>
	<li>In case there are not enough questions for the full exercise session, we
	will stop it early.</li>
	<li>There is no need to attend both exercise sessions, as their contents
	will be equivalent.</li>
</ul>

<p><strong>Communication</strong></p>

<p>
All communication (like special announcements) will be sent out by e-mail.
</p>

<h2>Literature</h2>

<p>
For students who would like to brush up on the basics of machine learning used
in this course, we recommend
</p>

<ul>
	<li>Section 3 (Background) of the publication <a
	href="https://files.sri.inf.ethz.ch/website/papers/DeepPoly.pdf">An Abstract
	Domain for Certifying Neural Networks</a> by Gagandeep Singh, Timon Gehr,
	Markus Püschel, and Martin Vechev</li>
	<li><a href="http://neuralnetworksanddeeplearning.com/index.html">Neural
	Networks and Deep Learning</a> by Michael Nielsen</li>
	<li><a href="https://www.deeplearningbook.org/">Deep Learning book</a>
	by Ian Goodfellow, Yoshua Bengio, and Aaron Courville</li>
</ul>
