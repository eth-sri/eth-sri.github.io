---
layout: page
---

        <div id="content">

                <div class="post">

                         <h3>POPL2019-Artifact-Paper264</h3>

<b>Artifact </b><br><br>

We provide our artifact in the form of a virtual machine running Ubuntu 18.04 which can be downloaded <a href="http://files.srl.inf.ethz.ch/POPL2019.ova">here</a>.
We prepared the virtual machine on a 10 Core 3.3 GHz  Intel i9-7900X Processor running Ubuntu 17.10. We allocated 4 GB of RAM to the virtual machine.

<br><br><b>Paper #264</b><br>
An Abstract Domain for Certifying Neural Networks <br><a href="http://files.srl.inf.ethz.ch/popl19-paper264.pdf" class="pdf"><img class="svg-icon" src="/assets/icons/icon-pdf.svg"></a> </li>
 

<br><br><br><b>System Requirements<br> </b>
 
	<ol>
	<li>Make sure you have 64-bit VirtualBox from Oracle.</li>
	<li> The virtual machine requires at least 8 GB of disk space. </li>
	<li>We recommend allocating at least 4 GB RAM to the virtual machine for analyzing larger benchmarks. </li>
	</ol>

<br><b>Instructions<br> </b>
<ol>
<li> Import the virtual machine in VirtualBox. More information on importing virtual machine in VirtualBox can be found <a href="https://docs.oracle.com/cd/E26217_01/E26796/html/qs-import-vm.html">here.</a>
<li>The login credentials for the Virtual Machine are:
		<ul>username: popl19-paper264</ul>
		<ul>password: paper264</ul></li>
<li> As the Virtual machine is already large, we did not include the learning data as well as the benchmarks used for training. </li>
 </ol>
<br><b> Neural Networks <br></b>
<li>The MNIST feedforward and convolutional network used in our evaluation can be found in the "DeepPoly/nets/mnist/feedforward" and "DeepPoly/nets/mnist/conv" directories respectively.</li>
<li>Similarly the CIFAR neural networks can be found in the "DeepPoly/nets/cifar/feedforward" and "DeepPoly/nets/cifar/conv" directories.</li>


<br><b> Specs <br></b>
<li>The images for the MNIST networks can be found in "DeepPoly/specs/mnist" directory. This folder has three subdirectories: 
<ul>The "null2" directory contains the 10 original images used in our evaluation</ul>
<ul>The "L_infinity" directory contains the L_infinity robustness specifications for the 10 images with 6 different epsilons (specified in the name) </ul>
<ul>The "total_tight" directory contains the brightness specifications for the 10 images with 6 different epsilons. The epsilon value for a given specification file can be determined by subtracting the number in the name of the file from 1, e.g., img0_spec_black0.915.txt corresponds to img0 perturbed with an epsilon of 0.085.</ul>
<ul> The "rotations" directory contains the L_infinity norm perturbed image for the rotation attack.</li>
<li>Similarly the CIFAR specs can be found in the "DeepPoly/specs/cifar/null2", "DeepPoly/specs/cifar/L_infinity", and "DeepPoly/specs/cifar/total_tight" directories. </li> 
<li> Note that the range of images for the CIFAR dataset is -0.5 to 0.5 compard to 0 to 1 for MNIST.</li>


<br><b>Analyzers<br> </b>
<ol>
<li> DeepPoly </li>
<ul> The analysis with our abstract domain for the feedforward and convolutional networks can be found in the files "DeepPoly/analyzers/deeppoly_ffn.py" and "DeepPoly/analyzers/deeppoly_conv.py" directory.</ul> 
<ul>The abstract domain implementation builds on top of the ELINA library. The domain implementation can be found in the "DeepPoly/ELINA/fppoly" directory. We have already precompiled and install ELINA in the virtual machine. </ul>
<ul>The source code for handling the rotations can be found in the directory "DeepPoly/refinement".</ul>
</li>
<li> FastLin
<ul> We have adapted the parser for <a href="https://github.com/huanzhang12/CertifiedReLURobustness"> FastLin </a> to work with our networks. The analysis stays the same.</ul>
<ul> The files "DeepPoly/analyzers/fastlin_L_infinity_mnist.py" and "DeepPoly/analyzers/fastlin_brighness_mnist.py" respectively verify the robustness of MNIST feedforward network against L_infinity and brightness attacks.</ul>
<ul> The files "DeepPoly/analyzers/fastlin_L_infinity_cifar.py" and "DeepPoly/analyzers/fastlin_brighness_cifar.py" respectively verify the robustness of CIFAR feedforward network against L_infinity and brightness attacks.</ul>
</li>
<li> AI2 </li>
<ul>The source code for AI2 can be found in the directory "ai2/nn_ai".</ul>
<ul> AI2 can work with Interval, Polyhedra, and Zonotope domains. We have already compiled AI2 to work with the Zonotope domain implementation from ELINA (the best known configuration for AI2) found in "DeepPoly/ELINA/elina_zonotope".</ul></li>
<li> Fastlin takes an original image and then perturbs it with a given epsilon whereas DeepPoly and AI2 work directly the specification files in the "L_infinity" and "total_tight" directories. </li>
</ol>



<br><b>Reproducing results<br> </b>
<ol>
<li>For reproducing results for the L_infinity and brightness attacks reported in the paper, run "sudo run.sh" in "DeepPoly/scripts" directory. It first runs DeepPoly analysis on all MNIST and CIFAR networks with L_infinity and brightness specifications, followed by FastLin (only feedforward networks considered) and AI2.  </li>
<li>The script first displays the analyzer type, then the network type on the screen. Next it displays the robustness property being verified which includes the name of the image, the epsilon used and the type of attack. Note that for the brightness attack, the script displays "1-epsilon" for DeepPoly and AI2 and "epsilon" for FastLin. </li>
 <li>  The verification and timing results are collected in the "results" directory. The files ending with "robustness" contains the verification results and "timing" contains the runtime in seconds. If the neural network is robust under an adverserial attack then "verified" is printed otherwise "Failed" is printed.</li>
<li> The "run.sh" script also produces a summary of the results comparing the robustness and runtimes of all three analyzers in the "DeepPoly/result_summary" directory. The summary files ending with "robustness" contain the percentage of specifications proved to be robust for each analyzer per epsilon value whereas the files ending with "timing" contain the average runtime in seconds per epsilon value. </li>
<li> Note that for the analysis of a given neural network under a given attack, if an analyzer runs out of memory or is stopped by the user, the script "run.sh" will continue with the next specification however no summary file will be produced (or the results may be inconsistent). However, it is still possible to view the results for the other specification in the "results" directory. This can happen for example in the evaluation of the convolutional networks with AI2 where it frequently either runs out of memory or takes too long.</li>
<li> For reproducing the result for the rotation specifications, first run "experiments.sh" in the "DeepPoly/refinement" folder, this will run the rotation algorithm with different number of batches and batch sizes and generate the corresponding rotated images. Next run "run_experiments.sh", this will run the DeepPoly analysis on the different rotated images and print the verification result and the runtime in seconds.
</ol>

<br><b>Caveats<br> </b><ol>
	<li> The analysis runs slower on the virtual machine and the timings vary considerably. We have observed upto 2x slowdowns for the analysis of larger networks. </li>

	</ol>

                </div>
        </div>


