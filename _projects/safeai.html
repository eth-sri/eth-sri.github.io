---
title: Safe and Interpretable Artificial Intelligence
ref: safeai
image: smart.png
description: "In this project we explore new methods and systems which can reason about AI safety, including deep learning. Concretely, we have introduced new approaches and tools for certifying and training robust and interpretable deep neural networks."


---

<h2>Systems</h2>
<div class="grid">
  {% include card.html
    title="Safe Artificial Intelligence via Abstract Interpretation"
    output="vertical"
    url="http://safeai.ethz.ch/"
    image="/assets/systems/safeai-logo.png"
    description="Certifying and training robust neural networks using approaches based on abstract interpretation."
  %}
</div>


<h2>Publications</h2>

{% include get-publications.html filter="project" key="safeai" %}


<h2>Talks</h2>

{% include card.html
  title="Safe and Robust Deep Learning"
  url="https://ece.uwaterloo.ca/~MLSecurity/index.html"
  output="horizontal"
  description="Waterloo ML + Security + Verification Workshop"
  slides="https://files.sri.inf.ethz.ch/website/slides/Waterloo19-SafeAI.pdf"
%}

{% include card.html
  title="Safe and Robust Deep Learning"
  url="https://blogs.ed.ac.uk/rai-nr/"
  output="horizontal"
  description="University of Edinburgh, Robust Artificial Intelligence for Neurorobotics 2019"
  slides="https://files.sri.inf.ethz.ch/website/slides/Edinburgh19-SafeAI.pdf"
%}

{% include card.html
  title="AI2: AI Safety and Robustness with Abstract Interpretation"
  url="https://www.floc2018.org/summit-on-machine-learning/"
  output="horizontal"
  description="Machine Learning meets Formal Methods, FLOC 2018"
  slides="https://files.sri.inf.ethz.ch/website/slides/FLOC18-AI2.pdf"
%}
