---
ref: mirman2018differentiable
title: Differentiable Abstract Interpretation for Provably Robust Neural Networks
authors: Matthew Mirman, Timon Gehr, Martin Vechev
year: 2018
month: 07
venue: ICML
projects: safeai
awards:
bibtex: '@inproceedings{mirman2018differentiable,
  title={Differentiable Abstract Interpretation for Provably Robust Neural Networks},
  author={Mirman, Matthew and Gehr, Timon and Vechev, Martin},
  booktitle={International Conference on Machine Learning},
  pages={3575--3583},
  year={2018}}'
paper: https://files.sri.inf.ethz.ch/website/papers/icml18-diffai.pdf
talk: 
slides: mirman2018differentiable.pdf
---

We introduce a scalable method for training robust neural networks based on abstract interpretation. We present several abstract transformers which balance efficiency with precision and show these can be used to train large neural networks that are certifiably robust to adversarial perturbations.
