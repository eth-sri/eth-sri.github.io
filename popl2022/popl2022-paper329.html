---
layout: page
---

        <div id="content">

                <div class="post">

                         <h3>POPL2022-Artifact-Paper329</h3>

<b>Artifact </b><br><br>

We provide our artifact in the form of a virtual machine running Ubuntu 18.04 which can be downloaded <a href="http://files.srl.inf.ethz.ch/popl2022-paper329_vm.zip">here</a>.
If the download does not start upon klicking on the link please use "wget http://files.srl.inf.ethz.ch/popl2022-paper329_vm.zip".
We prepared the virtual machine on a 16 Core 3.6 GHz Intel i9-9900K Processor with NVIDIA RTX 2080 Ti. <!We allocated 4 GB of RAM to the virtual machine.!>

<br><br><b>Paper #329</b><br>
PRIMA: General and Precise Neural Network Certification via Scalable Convex Hull Approximations <br><a href="https://files.sri.inf.ethz.ch/website/papers/mueller2021precise.pdf" class="pdf"><img class="svg-icon" src="/assets/icons/icon-pdf.svg"></a> </li>

<br><br><br><b>System Requirements<br> </b>
 
	<ol>
	<li>Make sure you have 64-bit VirtualBox from Oracle.</li>
	<li> The virtual machine requires at least 20 GB of disk space. </li>
	<li>We recommend allocating at least 16 GB RAM to the virtual machine for analyzing larger benchmarks. </li>
	</ol>

<br><b>Instructions<br> </b>
<ol>
<li> Import the virtual machine in VirtualBox. More information on importing virtual machine in VirtualBox can be found <a href="https://docs.oracle.com/cd/E26217_01/E26796/html/qs-import-vm.html">here.</a>
<li>The login credentials for the Virtual Machine are:
		<ul>username: popl22-paper329</ul>
		<ul>password: paper329</ul></li>
 </ol>
<br><b> Neural Networks <br></b>
<li>All MNIST networks used in our evaluation can be found in the "prima_popl_artifact/prima/eran/nets/mnist" directory.</li>
<li>Similarly, all CIFAR and DAVE neural networks can be found in the "prima_popl_artifact/prima/eran/nets/cifar10" and "prima_popl_artifact/prima/eran/nets/DAVE" directories, respectively.</li>


<br><b> Specs <br></b>
<li>The images for the MNIST networks can be found in "prima_popl_artifact/prima/eran/data/mnist_test_full.csv". The following subsets were used:
<ul>The first 1000 images for the main results reported on ReLU networks (Table 2).</ul>
<ul>The first 100 images for the evaluation of hyperparameters in Table 4.</ul>
<ul>The first 100 images for all results reported on Tanh and Sigmoid networks (Table 5).</ul>
<li>For CIFAR10, we use the following specs:
<ul>The first 1000 images of the test set ("prima_popl_artifact/prima/eran/data/cifar10_test_full.csv") for the main results reported in Table 2.</ul>
<ul>The 100 images Wang et. al. 2021 provide for the evaluation of Beta-CROWN for CNN-A-Mix ("prima_popl_artifact/prima/eran/data/cifar10_test_a_mix.csv") and CNN-B-Adv ("prima_popl_artifact/prima/eran/data/cifar10_test_b_adv.csv") for the comparison in Table 3.</ul>
<li>The DAVE images corresponding the frames of video 4 can be found in the "prima_popl_artifact/prima/eran/data/dave/all".</li>


<br><b>Analyzers<br> </b>
<ol>
<li> PRIMA
<ul> PRIMA is integrated into the ERAN framework, it can be run by specifying the domain "refinepoly" (or "refinegpupoly"). The corresponding source code can be found in the directory "prima_popl_artifact/prima/eran/tf_verify".</ul>
<li> DeepPoly
<ul> DeepPoly is integrated into the ERAN framework, it can be run by specifying the domain "deeppoly". The corresponding source code can be found in the directory "prima_popl_artifact/prima/eran/tf_verify".</ul>
<li> GPUPoly
<ul> GPUPoly is integrated into the ERAN framework, it can be run by specifying the domain "gpupoly". The corresponding source code can be found in the directory "prima_popl_artifact/prima/eran/tf_verify".</ul>
<li> kPoly
<ul> kPoly is also based on the ERAN framework, but requires an older version of ELINA not compatible with the current ERAN code. Hence we include the source code in the separate directory "prima_popl_artifact/kpoly/eran".</ul>
</ol>



<br><b>Reproducing results<br> </b>
<ol>
<li>To reproduce all PRIMA results with using GPU go to the directory "prima_popl_artifact/prima/eran/tf_verify" and first "source init.sh" to prepare the correct ELINA version and activate the right conda environment and then run "bash run_all_experiments_no_gpu.sh".</li>
<li>To reproduce all PRIMA results with the configurations used to obtain the results reported in the paper, a GPU is needed. Hence this is not possible in the VirtualMachine. However we provide all the corresponding configs in "prima_popl_artifact/prima/eran/tf_verify/run_all_experiments.sh" and note that all ERAN code is published and can be found <a href="https://github.com/eth-sri/eran">here.</a> </li>
<li> To reproduce all kPoly baselines, go to the directory "prima_popl_artifact/kpoly/eran/tf_verify" and first "source init.sh" to prepare the correct ELINA version and activate the right conda environment and then run "bash run_kPoly.sh". </li>
<li> As both reproducing our results and the baselines takes multiple weeks of runtime even with a strong CPU outside of a virtual machine, we provide our log files for the reviewers convenience. Please find all logs for PRIMA results at "prima_popl_artifact/prima/eran/experiment_logs_prerun" and all logs for baselines at "prima_popl_artifact/prima/eran/baseline_logs". Additionally, we prepared "prima_popl_artifact/prima/eran/tf_verify/run_experiments_quick_subset.sh" to run some comparatively fast benchmarks (some with reduced sample count).</li>
</ol>

<br><b>Caveats<br></b>
<ol>
<li> The analysis runs slower on the virtual machine than on the host processor. As we use timeouts to interrupt our analysis after a predetermined runtime, this can reduce the obtained certified accuracy and increase average runtime.</li>
<li> All convolutional networks use GPUPoly to compute the input regions used to compute multi-neuron constraints. While using DeepPoly instead yields the same result the runtime is significantly slower, especially for ConvBig and the autonomous driving networks.</li>	
<li> Recomputing all results even with GPU access takes multiple weeks. Hence, we have provided the log files corresponding to our results and the baselines we report as described above for the reviewers convenience.</li>	
</ol>

                </div>
        </div>


